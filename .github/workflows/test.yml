name: NHI Security Testbed Tests

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of tests to run'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - unit
          - smoke
          - integration
          - e2e

env:
  WAZUH_MANAGER_URL: https://localhost:55000
  WAZUH_API_USER: wazuh-wui
  WAZUH_API_PASSWORD: ${{ secrets.WAZUH_API_PASSWORD || 'MyS3cr3tP4ssw0rd*!' }}
  WAZUH_INDEXER_URL: https://localhost:9200
  WAZUH_INDEXER_USER: admin
  WAZUH_INDEXER_PASSWORD: ${{ secrets.WAZUH_INDEXER_PASSWORD || 'SecretPassword' }}

jobs:
  # Unit tests - no Docker required
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements.txt

      - name: Run unit tests
        run: |
          cd tests
          pytest -v -m unit --tb=short --junitxml=../reports/unit-results.xml

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unit-test-results
          path: reports/unit-results.xml

  # Rule validation - no Docker required
  rule-validation:
    name: Rule Validation
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install lxml pytest

      - name: Validate rule XML syntax
        run: |
          python -c "
          from lxml import etree
          from pathlib import Path
          rules_dir = Path('wazuh/rules')
          if rules_dir.exists():
              for f in rules_dir.glob('*.xml'):
                  try:
                      etree.parse(str(f))
                      print(f'OK: {f.name}')
                  except Exception as e:
                      print(f'ERROR: {f.name}: {e}')
                      exit(1)
          "

      - name: Validate decoder XML syntax
        run: |
          python -c "
          from lxml import etree
          from pathlib import Path
          decoders_dir = Path('wazuh/decoders')
          if decoders_dir.exists():
              for f in decoders_dir.glob('*.xml'):
                  try:
                      etree.parse(str(f))
                      print(f'OK: {f.name}')
                  except Exception as e:
                      print(f'ERROR: {f.name}: {e}')
                      exit(1)
          "

  # Integration tests - requires Docker
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [unit-tests, rule-validation]
    if: github.event_name == 'workflow_dispatch' || github.ref == 'refs/heads/main'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements.txt

      - name: Start testbed
        run: |
          docker compose up -d
          echo "Waiting for services to be ready..."
          sleep 60

      - name: Check service health
        run: |
          docker compose ps
          docker compose logs --tail=20

      - name: Run smoke tests
        run: |
          cd tests
          pytest -v -m smoke --tb=short --timeout=120 || true

      - name: Run integration tests
        run: |
          cd tests
          pytest -v -m integration --tb=short --timeout=300 \
            --junitxml=../reports/integration-results.xml || true

      - name: Collect logs on failure
        if: failure()
        run: |
          mkdir -p reports/logs
          docker compose logs > reports/logs/docker-compose.log

      - name: Stop testbed
        if: always()
        run: docker compose down -v

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-test-results
          path: reports/

  # E2E tests by category - matrix strategy
  e2e-tests:
    name: E2E Tests - Category ${{ matrix.category }}
    runs-on: ubuntu-latest
    needs: [integration-tests]
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.test_type == 'e2e'
    strategy:
      fail-fast: false
      matrix:
        category: [1, 2, 3]
        # Categories 4 and 5 require special profiles
        # category: [1, 2, 3, 4, 5]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r tests/requirements.txt

      - name: Start testbed
        run: |
          docker compose up -d
          echo "Waiting for services to be ready..."
          sleep 90

      - name: Run E2E tests for category ${{ matrix.category }}
        run: |
          cd tests
          pytest -v -m "category_${{ matrix.category }}" --tb=short --timeout=600 \
            --junitxml=../reports/e2e-category-${{ matrix.category }}-results.xml || true

      - name: Collect logs
        if: always()
        run: |
          mkdir -p reports/logs
          docker compose logs > reports/logs/e2e-category-${{ matrix.category }}.log

      - name: Stop testbed
        if: always()
        run: docker compose down -v

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-category-${{ matrix.category }}-results
          path: reports/

  # Generate test report
  generate-report:
    name: Generate Test Report
    runs-on: ubuntu-latest
    needs: [unit-tests, rule-validation]
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: all-results

      - name: Generate summary
        run: |
          echo "# Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Test Types Run" >> $GITHUB_STEP_SUMMARY
          echo "- Unit Tests: ${{ needs.unit-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Rule Validation: ${{ needs.rule-validation.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Artifacts" >> $GITHUB_STEP_SUMMARY
          ls -la all-results/ 2>/dev/null || echo "No artifacts found"
